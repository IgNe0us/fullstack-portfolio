import os
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

# 1. ë°ì´í„° ë¡œë“œ (my_vacuum.pdf)
# í˜„ì¬ í´ë”ì— ìˆëŠ” ë‹˜ì˜ ì´ë ¥ì„œ PDFë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
loader = PyMuPDFLoader("manual.pdf")
docs = loader.load()

print(f"âœ… PDFì—ì„œ {len(docs)}ê°œì˜ í˜ì´ì§€ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

# 2. ë°ì´í„° ìª¼ê°œê¸° (Chunking)
# PDF ë‚´ìš©ì„ 1000ì ë‹¨ìœ„ë¡œ ìª¼ê°œê³ , 100ìì”© ê²¹ì¹˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
splits = text_splitter.split_documents(docs)

print(f"âœ… ë¬¸ì„œë¥¼ {len(splits)}ê°œì˜ ì¡°ê°(chunk)ìœ¼ë¡œ ë‚˜ëˆ´ìŠµë‹ˆë‹¤.")

# 3. ì„ë² ë”© ëª¨ë¸ ì„ íƒ (Ko-SBERT)
# í…ìŠ¤íŠ¸ë¥¼ 'ìˆ«ì ë²¡í„°'ë¡œ ë³€í™˜í•  ëª¨ë¸(Ko-SBERT)ì„ ë¡œë“œí•©ë‹ˆë‹¤.
# (ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠë¼ ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
model_name = "jhgan/ko-sbert-nli"
model_kwargs = {'device': 'cpu'} # GPUê°€ ìˆë‹¤ë©´ 'cuda'ë¡œ ë³€ê²½
encode_kwargs = {'normalize_embeddings': True}
embeddings = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)

print("âœ… ì„ë² ë”© ëª¨ë¸(Ko-SBERT) ë¡œë“œ ì™„ë£Œ.")

# 4. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ (FAISS)
# ìª¼ê°  ë¬¸ì„œ ì¡°ê°(splits)ë“¤ì„ ëª¨ë‘ 'ìˆ«ì ë²¡í„°'ë¡œ ë³€í™˜í•˜ì—¬
# 'faiss_index_vacuum' ë¼ëŠ” í´ë”ì— DBë¡œ ì €ì¥í•©ë‹ˆë‹¤.
vectorstore = FAISS.from_documents(splits, embeddings)
vectorstore.save_local("faiss_index_vacuum")

print("ğŸ‰ ì„±ê³µ: ë²¡í„° ìŠ¤í† ì–´(FAISS) ìƒì„± ì™„ë£Œ! 'faiss_index_vacuum' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")